{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c01952-6616-483e-992d-3eae7319162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "class HardDistillationLoss(nn.Module):\n",
    "    def __init__(self, teacher: nn.Module):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, inputs: Tensor, outputs : Tensor, labels: Tensor) -> Tensor:\n",
    "        \n",
    "        base_loss = self.criterion(outputs, labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = self.teacher(inputs)\n",
    "        teacher_labels = torch.argmax(teacher_outputs, dim=1)\n",
    "        teacher_loss = self.criterion(outputs, teacher_labels)\n",
    "        \n",
    "        return 0.5 * base_loss + 0.5 * teacher_loss\n",
    "    \n",
    "# little test   \n",
    "loss = HardDistillationLoss(nn.Linear(100, 10))\n",
    "_ = loss(torch.rand((8, 100)), torch.rand((8, 10)), torch.ones(8).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c473c6-ac3b-425d-ad33-c3f31b2647b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class HardDistillationLoss(nn.Module):\n",
    "    def __init__(self, teacher: nn.Module):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, inputs: Tensor, outputs: Union[Tensor, Tensor], labels: Tensor) -> Tensor:\n",
    "        # outputs contains booth predictions, one with the cls token and one with the dist token\n",
    "        outputs_cls, outputs_dist = outputs\n",
    "        base_loss = self.criterion(outputs_cls, labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = self.teacher(inputs)\n",
    "        teacher_labels = torch.argmax(teacher_outputs, dim=1)\n",
    "        teacher_loss = self.criterion(outputs_dist, teacher_labels)\n",
    "        \n",
    "        return 0.5 * base_loss + 0.5 * teacher_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039b52d-9330-4ed6-8ce0-aa290cc1329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size: int = 224):\n",
    "        self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        # distillation token\n",
    "        self.dist_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
    "\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.projection(x)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        dist_tokens = repeat(self.dist_tokens, '() n e -> b n e', b=b)\n",
    "        # prepend the cls token to the input\n",
    "        x = torch.cat([cls_tokens, dist_tokens, x], dim=1)\n",
    "        # add position embedding\n",
    "        x += self.positions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003fc86-1804-46b8-8388-3f3b699b4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, emb_size: int = 768, n_classes: int = 1000):       \n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Linear(emb_size, n_classes)\n",
    "        self.dist_head = nn.Linear(emb_size, n_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, x_dist = x[:, 0], x[:, 1]\n",
    "        x_head = self.head(x)\n",
    "        x_dist_head = self.dist_head(x_dist)\n",
    "        \n",
    "        if self.training:\n",
    "            x = x_head, x_dist_head\n",
    "        else:\n",
    "            x = (x_head + x_dist_head) / 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be3302-a848-44fa-b505-e9810e3de3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        # fuse the queries, keys and values in one matrix\n",
    "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "        \n",
    "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
    "        # split keys, queries and values in num_heads\n",
    "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
    "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
    "        # sum up over the last axis\n",
    "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill(~mask, fill_value)\n",
    "            \n",
    "        scaling = self.emb_size ** (1/2)\n",
    "        att = F.softmax(energy, dim=-1) / scaling\n",
    "        att = self.att_drop(att)\n",
    "        # sum up over the third axis\n",
    "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.projection(out)\n",
    "        return out\n",
    "    \n",
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        res = x\n",
    "        x = self.fn(x, **kwargs)\n",
    "        x += res\n",
    "        return x\n",
    "    \n",
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size: int, expansion: int = 4, drop_p: float = 0.):\n",
    "        super().__init__(\n",
    "            nn.Linear(emb_size, expansion * emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(expansion * emb_size, emb_size),\n",
    "        )\n",
    "        \n",
    "class TransformerEncoderBlock(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 emb_size: int = 768,\n",
    "                 drop_p: float = 0.,\n",
    "                 forward_expansion: int = 4,\n",
    "                 forward_drop_p: float = 0.,\n",
    "                 ** kwargs):\n",
    "        super().__init__(\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                nn.LayerNorm(emb_size),\n",
    "                MultiHeadAttention(emb_size, **kwargs),\n",
    "                nn.Dropout(drop_p)\n",
    "            )),\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                nn.LayerNorm(emb_size),\n",
    "                FeedForwardBlock(\n",
    "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
    "                nn.Dropout(drop_p)\n",
    "            )\n",
    "            ))\n",
    "\n",
    "class TransformerEncoder(nn.Sequential):\n",
    "    def __init__(self, depth: int = 12, **kwargs):\n",
    "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9766a7-e8df-431a-87a3-d73d069c942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeiT(nn.Sequential):\n",
    "    def __init__(self,     \n",
    "                in_channels: int = 3,\n",
    "                patch_size: int = 16,\n",
    "                emb_size: int = 768,\n",
    "                img_size: int = 224,\n",
    "                depth: int = 12,\n",
    "                n_classes: int = 1000,\n",
    "                **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
    "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
    "            ClassificationHead(emb_size, n_classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743089b-d5ef-4a7d-806e-c84c9d44c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageDataset('TestingAndTrainingFinal_min')\n",
    "dl = DataLoader(ds, ...)\n",
    "\n",
    "teacher = ViT.vit_large_patch16_224()\n",
    "student = DeiT.deit_small_patch16_224()\n",
    "\n",
    "optimizer = Adam(student.parameters())\n",
    "criterion = HardDistillationLoss(teacher)\n",
    "\n",
    "for data in dl:\n",
    "    inputs, labels = data\n",
    "    outputs = student(inputs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = criterion(inputs, outputs, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446eff6-97a4-4b48-8b48-8542395ca95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
